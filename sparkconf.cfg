[KUBERNETES]
spark.kubernetes.authenticate.caCertFile=/var/snap/microk8s/current/certs/ca.crt
spark.kubernetes.authenticate.oauthToken=OHVYSWhabXlFdHNwbnhYKzV6N0FoSmJ4SEs5OWR3ektybE5ETXRYQUQ0UT0K
spark.kubernetes.namespace=spark-notebooks
spark.kubernetes.container.image=dutradocker/spark-py:3.2.0
spark.kubernetes.container.image.pullPolicy=Always
spark.kubernetes.authenticate.driver.serviceAccountName=spark

[JARS]
spark.jars.packages=org.apache.hadoop:hadoop-aws:3.2.2,org.apache.sedona:sedona-python-adapter-3.0_2.12:1.1.1-incubating,org.datasyslab:geotools-wrapper:1.1.0-25.2

[HADOOP]
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.path.style.access=true

[DRIVER]
spark.driver.extraJavaOptions=-Dcom.amazonaws.sdk.disableCertChecking=true

[SPARK]
spark.master=k8s://127.0.0.1:16443
spark.app.name=Local spark session

[EXECUTOR]
spark.executor.extraJavaOptions=-Dcom.amazonaws.sdk.disableCertChecking=true
spark.executor.instances=3
spark.executor.memory=5g
spark.executor.cores=1

[S3]
spark.hadoop.fs.s3a.endpoint=https://minio.minio-tenant
spark.hadoop.fs.s3a.access.key=admin
spark.hadoop.fs.s3a.secret.key=6bd71ace-8866-407a-9bcc-714bc5753f18

# [S3]
# spark.hadoop.fs.s3a.endpoint=https://s3.amazonaws.com
# spark.hadoop.fs.s3a.access.key=AKIA342YABPXELBNUT6Q
# spark.hadoop.fs.s3a.secret.key=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