{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (expr, broadcast, substring as s_substring, trim as s_trim)\n",
    "from pyspark.sql.types import (StructType, StructField, IntegerType, StringType)\n",
    "\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import KryoSerializer, SedonaKryoRegistrator\n",
    "from sedona.utils.adapter import Adapter\n",
    "from sedona.core.formatMapper.shapefileParser import ShapefileReader \n",
    "\n",
    "# import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkConf = SparkConf()\n",
    "parser = configparser.ConfigParser()\n",
    "parser.optionxform=str\n",
    "parser.read_file(open('../sparkconf.cfg'))\n",
    "\n",
    "for section, config in parser.items():\n",
    "    for key, value in config.items():\n",
    "        sparkConf.set(key, value)\n",
    "\n",
    "sparkConf.set(\"spark.serializer\", KryoSerializer.getName)\n",
    "sparkConf.set(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName)\n",
    "\n",
    "sparkConf.set(\"spark.archives\", \"https://minio.minio-tenant/dutrajardim-etls/dependencies.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=admin%2F20220228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220228T111424Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=a20e1526dd993354ae90c90c7cb76da4726a5ae00c9920ceec8e2a35f3482c3c#deps\")\n",
    "sparkConf.set(\"spark.executorEnv.PYTHONPATH\", \"/opt/spark/work-dir/deps\")\n",
    "sparkConf.set(\"spark.executorEnv.LD_LIBRARY_PATH\", \"/opt/spark/work-dir/deps/Shapely.libs\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.38:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>k8s://127.0.0.1:16443</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Local spark session</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f982e819940>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SedonaRegistrator.registerAll(spark)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd_adm0 = ShapefileReader.readToGeometryRDD(spark.sparkContext, \"s3a://dutrajardim-fi/src/shapes/gadm40/adm_0/*/\")\n",
    "rdd_adm0 = rdd_adm0.rawSpatialRDD.map(lambda x: (x.geom.wkt, *x.userData.split(\"\\t\")))\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"geometry\", StringType(), False),\n",
    "        StructField(\"name\", StringType(), False),\n",
    "        StructField(\"id\", StringType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "sdf_adm0 = rdd_adm0.toDF(schema=schema)\n",
    "sdf_adm0 = sdf_adm0.selectExpr(\n",
    "    \"id\",\n",
    "    \"geometry\",\n",
    "    \"DECODE(ENCODE(name, 'ISO-8859-1'), 'UTF-8') as name\"\n",
    ")\n",
    "\n",
    "# set dynamic mode to preserve previous month of times saved\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"static\")\n",
    "\n",
    "sdf_adm0.write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"s3a://dutrajardim-fi/tables/shapes/adm0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd_adm1 = ShapefileReader.readToGeometryRDD(spark.sparkContext, \"s3a://dutrajardim-fi/src/shapes/gadm40/adm_1/*/\")\n",
    "rdd_adm1 = rdd_adm1.rawSpatialRDD.map(lambda x: (x.geom.wkt, *x.userData.split(\"\\t\")))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"geometry\", StringType(), False),\n",
    "    StructField(\"adm0\", StringType(), False),\n",
    "    StructField(\"adm0_name\", StringType(), False),\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"varname\", StringType(), False),\n",
    "    StructField(\"nl_name\", StringType(), False),\n",
    "    StructField(\"type\", StringType(), False),\n",
    "    StructField(\"eng_type\", StringType(), False),\n",
    "    StructField(\"cc\", StringType(), False),\n",
    "    StructField(\"hasc\", StringType(), False),\n",
    "    StructField(\"iso\", StringType(), False),\n",
    "])\n",
    "\n",
    "sdf_adm1 = rdd_adm1.toDF(schema=schema)\n",
    "sdf_adm1 = sdf_adm1.selectExpr(\n",
    "    \"id\",\n",
    "    \"geometry\",\n",
    "    \"DECODE(ENCODE(name, 'ISO-8859-1'), 'UTF-8') as name\",\n",
    "    \"adm0\"\n",
    ")\n",
    "\n",
    "# set dynamic mode to preserve previous month of times saved\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"static\")\n",
    "\n",
    "sdf_adm1.write \\\n",
    "    .partitionBy(\"adm0\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"s3a://dutrajardim-fi/tables/shapes/adm1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd_adm2 = ShapefileReader.readToGeometryRDD(spark.sparkContext, \"s3a://dutrajardim-fi/src/shapes/gadm40/adm_2/*/\")\n",
    "rdd_adm2 = rdd_adm2.rawSpatialRDD.map(lambda x: (x.geom.wkt, *x.userData.split(\"\\t\")))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"geometry\", StringType(), False),\n",
    "    StructField(\"adm0\", StringType(), False),\n",
    "    StructField(\"adm0_name\", StringType(), False),\n",
    "    StructField(\"adm1_name\", StringType(), False),\n",
    "    StructField(\"adm1_nl_name\", StringType(), False),\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"varname\", StringType(), False),\n",
    "    StructField(\"nl_name\", StringType(), False),\n",
    "    StructField(\"type\", StringType(), False),\n",
    "    StructField(\"eng_type\", StringType(), False),\n",
    "    StructField(\"cc\", StringType(), False),\n",
    "    StructField(\"hasc\", StringType(), False)\n",
    "])\n",
    "\n",
    "sdf_adm2 = rdd_adm2.toDF(schema=schema)\n",
    "sdf_adm2 = sdf_adm2.selectExpr(\n",
    "    \"id\",\n",
    "    \"geometry\",\n",
    "    \"DECODE(ENCODE(name, 'ISO-8859-1'), 'UTF-8') as name\",\n",
    "    \"adm0\",\n",
    "    \"CONCAT(CONCAT_WS('.', SLICE(SPLIT(id, '\\\\\\\\.'), 1, 2)), '_1') as adm1\"\n",
    ")\n",
    "\n",
    "# set dynamic mode to preserve previous month of times saved\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"static\")\n",
    "\n",
    "sdf_adm2.write \\\n",
    "    .partitionBy([\"adm0\", \"adm1\"]) \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"s3a://dutrajardim-fi/tables/shapes/adm2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd_adm3 = ShapefileReader.readToGeometryRDD(spark.sparkContext, \"s3a://dutrajardim-fi/src/shapes/gadm40/adm_3/*/\")\n",
    "rdd_adm3 = rdd_adm3.rawSpatialRDD.map(lambda x: (x.geom.wkt, *x.userData.split(\"\\t\")))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"geometry\", StringType(), False),\n",
    "    StructField(\"adm0\", StringType(), False),\n",
    "    StructField(\"adm0_name\", StringType(), False),\n",
    "    StructField(\"adm1_name\", StringType(), False),\n",
    "    StructField(\"adm1_nl_name\", StringType(), False),\n",
    "    StructField(\"adm2_name\", StringType(), False),\n",
    "    StructField(\"adm2_nl_name\", StringType(), False),\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"varname\", StringType(), False),\n",
    "    StructField(\"nl_name\", StringType(), False),\n",
    "    StructField(\"type\", StringType(), False),\n",
    "    StructField(\"eng_type\", StringType(), False),\n",
    "    StructField(\"cc\", StringType(), False),\n",
    "    StructField(\"hasc\", StringType(), False)\n",
    "])\n",
    "\n",
    "sdf_adm3 = rdd_adm3.toDF(schema=schema)\n",
    "sdf_adm3 = sdf_adm3.selectExpr(\n",
    "    \"id\",\n",
    "    \"geometry\",\n",
    "    \"DECODE(ENCODE(name, 'ISO-8859-1'), 'UTF-8') as name\",\n",
    "    \"adm0\",\n",
    "    \"CONCAT(CONCAT_WS('.', SLICE(SPLIT(id, '\\\\\\\\.'), 1, 2)), '_1') as adm1\"\n",
    ")\n",
    "\n",
    "# set dynamic mode to preserve previous month of times saved\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"static\")\n",
    "\n",
    "sdf_adm3.write \\\n",
    "    .partitionBy([\"adm0\", \"adm1\"]) \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"s3a://dutrajardim-fi/tables/shapes/adm3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/28 18:42:22 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c77c8bc99c5ca9a742a1959efc4a0de604832b3555d74770d62233220eb12265"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
